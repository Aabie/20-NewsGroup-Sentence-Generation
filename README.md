# ğŸ“„ Sentence Generation with the 20 Newsgroups Dataset ğŸ§ ğŸ’¡  

This project explores **next sentence prediction** using the **20 Newsgroups dataset**. The dataset, spanning 20 diverse categories, provides an excellent foundation for training and evaluating text generation models.  

## Project Overview  
The goal of this project is to predict the next sentence given a text input, leveraging state-of-the-art generative models. This was achieved by:  
- Experimenting with four different language models:  
  - **DialoGPT-small**  
  - **GPT-Neo-125M**  
  - **GPT-2-small-x49**  
  - **GPT-2-base**  
- Preprocessing and analyzing the dataset to extract meaningful patterns.  
- Comparing model performance in generating contextually relevant and coherent sentences.  
- Fine-tuning and evaluating each model to optimize accuracy and contextual understanding.  

## Key Contributions  
ğŸ”¹ Preprocessed and analyzed text data to uncover insights across 20 categories.  
ğŸ”¹ Compared multiple models to identify the best approach for generating coherent text.  
ğŸ”¹ Deployed the final solution using **Streamlit** for an interactive, user-friendly experience.  

## Deployment  
The project has been deployed as a web application for interactive exploration of the results.  
ğŸŒ **Try the live demo here**: [20 News Group Sentence Generation App](https://20-news-group-sentence-generation.streamlit.app/)  

## Documentation  
Comprehensive documentation detailing the workflow, methodology, and findings of the project can be accessed at:  
ğŸ“˜ **Project Documentation**: [Fetch20 Newsgroups Text Generation](https://abienugraha.my.canva.site/fetch20-newsgroups-textgen)  

## Insights Gained  
This project provided valuable insights into:  
- The strengths and trade-offs of different generative models.  
- Techniques for sequence modeling and improving next-sentence predictions.  
- Practical implementation of NLP workflows from preprocessing to deployment.  

## Future Improvements  
- Incorporating larger datasets to enhance model generalization.  
- Exploring additional models like GPT-3 or fine-tuned T5 for more complex tasks.  
- Adding user input features to customize model parameters during predictions.  

## Acknowledgments  
Special thanks to the creators and maintainers of the **20 Newsgroups dataset** and the open-source tools that made this project possible.  

---  
### **Tags**  
#DataScience #NLP #NextSentencePrediction #MachineLearning #GenerativeAI  
